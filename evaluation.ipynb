{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from training.model_training import NN, get_loaders, get_accuracy\n",
    "from training.cnn import CNN, get_loaders_cnn\n",
    "\n",
    "from interface.interfacer import PseudoHardwareNN, PseudoHardwareCNN\n",
    "from interface.IOTransfer import quantize\n",
    "\n",
    "from hardware.crossbars import SimpleCrossbar, SimpleCrossbar2, DifferentialCrossbar\n",
    "from evaluator import compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"training/model.pth\"\n",
    "l1_model_path = \"training/model_l1reg.pth\"\n",
    "\n",
    "device = \"cpu\" # TODO need to fix for cuda and mps (atleast the software model)\n",
    "\n",
    "ann = NN()                                        \n",
    "# ann_reg = NN()\n",
    "# hwnn = PseudoHardwareNN(hardware_multiplier=SimpleCrossbar2, \n",
    "#                                         input_quantization=(True, 0.01),\n",
    "#                                         weight_quantization=(True, 0.05, [-1,1]),\n",
    "#                                         output_quantization=(True, 0.01),\n",
    "#                                         weight_variance=(True, 0.05),\n",
    "#                                         inline_resistances=(True, (1e-4, 1e-4)),\n",
    "#                                         verbose=False)\n",
    "\n",
    "# hwnn_l1reg = PseudoHardwareNN(hardware_multiplier=SimpleCrossbar2, \n",
    "#                                         input_quantization=(True, 0.01),\n",
    "#                                         weight_quantization=(True, 0.05, [-1,1]),\n",
    "#                                         output_quantization=(True, 0.01),\n",
    "#                                         weight_variance=(True, 0.05),\n",
    "#                                         inline_resistances=(True, (1e-4, 1e-4)),\n",
    "#                                         verbose=False)\n",
    "\n",
    "\n",
    "# hwnn2 = PseudoHardwareNN(hardware_multiplier=SimpleCrossbar2, \n",
    "#                                         input_quantization=(True, 0.01),\n",
    "#                                         weight_quantization=(True, 0.05, [-1,1]),\n",
    "#                                         output_quantization=(True, 0.01),\n",
    "#                                         inline_resistances=(True, (1e-4, 1e-4)))\n",
    "# hwnn3 = PseudoHardwareNN(hardware_multiplier=DifferentialCrossbar,\n",
    "#                                         input_quantization=(True, 0.01),\n",
    "#                                         weight_quantization=(True, 0.05, [-1,1]),\n",
    "#                                         output_quantization=(True, 0.01),\n",
    "#                                         inline_resistances=(True, (1e-4, 1e-4)))\n",
    "\n",
    "\n",
    "models = [ann] #, hwnn3]\n",
    "\n",
    "for model in models:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "# ann_reg.load_state_dict(torch.load(l1_model_path))\n",
    "# ann_reg.to(device)\n",
    "# ann_reg.eval()\n",
    "\n",
    "# models.append(ann_reg)\n",
    "\n",
    "# # hwnn_l1reg.load_state_dict(torch.load(l1_model_path))\n",
    "# # hwnn_l1reg.to(device)\n",
    "# # hwnn_l1reg.eval()\n",
    "\n",
    "# # models.append(hwnn_l1reg)\n",
    "\n",
    "# # dataset\n",
    "# test_data = get_loaders(batch_size=1, train=False, dataset_path=\"datasets/\")\n",
    "max_samples = None\n",
    "\n",
    "compare_models(models, names=['ann', 'hwnn', 'ann_reg'],max_samples=max_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar([\"Software\", \"Ideal Hardware\", \"QSI\"], [software_accuracy,hardware_accuracy, hardware_quantized_accuracy])\n",
    "# plt.hlines(software_accuracy, -0.5, 2.5, colors=\"r\", linestyles=\"dashed\", label=\"Software Baseline\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Model Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot weight distributions\n",
    "\n",
    "def plot_weights(model, layer_idx=None):\n",
    "\n",
    "    if layer_idx is not None:\n",
    "        for i, layer in enumerate(model.children()):\n",
    "            if i == layer_idx:\n",
    "                mylayer = layer\n",
    "                break\n",
    "\n",
    "        weights = mylayer.weight.detach().numpy().flatten()\n",
    "        plt.hist(weights, bins=100)\n",
    "        plt.title(f\"Layer {layer_idx} weights distribution\")\n",
    "        plt.show()\n",
    "\n",
    "    # side by side comparison\n",
    "    else:\n",
    "        total_layers = len(list(model.children()))\n",
    "        fig, axs = plt.subplots(1, total_layers, figsize=(20, 5))\n",
    "        \n",
    "\n",
    "        for i, layer in enumerate(model.children()):\n",
    "\n",
    "            weights = layer.weight.detach().numpy().flatten()\n",
    "            total_weights = len(weights)\n",
    "\n",
    "\n",
    "            color_list = [\"blue\", \"red\", \"green\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"cyan\", \"magenta\"]\n",
    "            axs[i].hist(weights, bins=100, color=color_list[i])\n",
    "            # axs[i].grid()\n",
    "\n",
    "            axs[i].set_xlabel(\"Weight Value\", fontsize=15)\n",
    "            axs[i].set_ylabel(\"Frequency\", fontsize=15)\n",
    "            axs[i].set_title(f\"Layer {i}; {total_weights} weights\", fontsize=15)\n",
    "\n",
    "            # tick size\n",
    "            axs[i].tick_params(axis='both', which='major', labelsize=12)\n",
    "            axs[i].tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # plt.savefig(\"weight_distributions.eps\", dpi = 600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "plot_weights(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(model, layer_idx=None):\n",
    "\n",
    "    if layer_idx is not None:\n",
    "        for i, layer in enumerate(model.children()):\n",
    "            if i == layer_idx:\n",
    "                mylayer = layer\n",
    "                break\n",
    "\n",
    "        weights = quantize(mylayer.weight.detach().numpy().flatten(), 0.05, [-1,1])\n",
    "\n",
    "        \n",
    "        plt.hist(weights, bins=100)\n",
    "        plt.title(f\"Layer {layer_idx} weights distribution\")\n",
    "        plt.show()\n",
    "\n",
    "    # side by side comparison\n",
    "    else:\n",
    "        total_layers = len(list(model.children()))\n",
    "        fig, axs = plt.subplots(1, total_layers, figsize=(20, 5))\n",
    "\n",
    "        for i, layer in enumerate(model.children()):\n",
    "            weights = quantize(layer.weight.detach().numpy().flatten(), 0.05, [-1,1]) + np.random.normal(0, 0.01, len(layer.weight.detach().numpy().flatten()))\n",
    "            total_weights = len(weights)\n",
    "\n",
    "            color_list = [\"blue\", \"red\", \"green\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"cyan\", \"magenta\"]\n",
    "            axs[i].hist(weights, bins=100, color=color_list[i])\n",
    "            # axs[i].grid()\n",
    "\n",
    "            axs[i].set_xlabel(\"Weight Value\", fontsize=15)\n",
    "            axs[i].set_ylabel(\"Frequency\", fontsize=15)\n",
    "            axs[i].set_title(f\"Layer {i}; {total_weights} weights\", fontsize=15)\n",
    "\n",
    "            # tick size\n",
    "            axs[i].tick_params(axis='both', which='major', labelsize=12)\n",
    "            axs[i].tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "\n",
    "        # plt.savefig(\"weight_distributions_quantized_variance.eps\", dpi = 600, bbox_inches='tight')        \n",
    "        plt.show()\n",
    "\n",
    "plot_weights(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def conv2mm(kernel, input_tensor):\n",
    "    \"\"\"\n",
    "    Returns the flattened kernel and corresponding 2D matrix of the input tensor\n",
    "    such that the convolution operation can be represented as a matrix multiplication\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = input_tensor.flatten()\n",
    "\n",
    "    # toeplitz matrix\n",
    "    kernel = kernel.flatten()\n",
    "    kernel_size = len(kernel)\n",
    "    input_size = len(input_tensor)\n",
    "    output_size = input_size - kernel_size + 1\n",
    "\n",
    "    toeplitz_matrix = np.zeros((output_size, input_size))\n",
    "\n",
    "    for i in range(output_size):\n",
    "        toeplitz_matrix[i, i:i+kernel_size] = kernel\n",
    "\n",
    "    return torch.tensor(toeplitz_matrix), input_tensor\n",
    "\n",
    "    \n",
    "\n",
    "## check correctness of conv2mm\n",
    "\n",
    "my_kernel = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "inputImage = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n",
    "\n",
    "toeplitz_matrix, input_tensor = conv2mm(my_kernel, inputImage)\n",
    "\n",
    "print(np.dot(toeplitz_matrix, input_tensor))\n",
    "# print(np.matmul(toeplitz_matrix, input_tensor))\n",
    "print(torch.nn.functional.conv2d(inputImage.unsqueeze(0).unsqueeze(0), my_kernel.unsqueeze(0).unsqueeze(0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"training/model.pth\"\n",
    "\n",
    "\n",
    "io_resolution = np.array([0.1]*10)\n",
    "weight_quantisation_list = 2**np.array([8])\n",
    "wtqt_list = 1/weight_quantisation_list\n",
    "weight_variability_list = np.array([1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "print(\"io,wtqt,wtvt,acc\")\n",
    "for ioqt in io_resolution:\n",
    "    for wtqt in wtqt_list:\n",
    "        models = []\n",
    "        for wtvt in weight_variability_list:\n",
    "            hwnn = PseudoHardwareNN(input_quantization=(True, ioqt),\n",
    "                                    weight_quantization=(True, wtqt, [-1,1]),\n",
    "                                    output_quantization=(True, ioqt),\n",
    "                                    weight_variance=(True, wtvt),\n",
    "                                    verbose=False)\n",
    "                                    \n",
    "            hwnn.load_state_dict(torch.load(model_path))\n",
    "            hwnn.eval()\n",
    "            models.append(hwnn)\n",
    "        \n",
    "        results = compare_models(models, np.arange(len(weight_variability_list)), max_samples=2000, get_accuracy=True, verbose=False)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"{ioqt}, {np.log2(1/wtqt)}, {weight_variability_list[i]}, {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"training/model.pth\"\n",
    "\n",
    "\n",
    "io_resolution = np.array([0.1]*5)\n",
    "weight_quantisation_list = 2**np.array([2,4,6,8,10])\n",
    "wtqt_list = 1/weight_quantisation_list\n",
    "weight_variability_list = np.array([1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "print(\"io,wtqt,wtvt,acc\")\n",
    "for ioqt in io_resolution:\n",
    "    for wtqt in wtqt_list:\n",
    "        models = []\n",
    "        for wtvt in weight_variability_list:\n",
    "            hwnn = PseudoHardwareNN(input_quantization=(True, ioqt),\n",
    "                                    weight_quantization=(True, wtqt, [-1,1]),\n",
    "                                    output_quantization=(True, ioqt),\n",
    "                                    weight_variance=(True, wtvt),\n",
    "                                    verbose=False)\n",
    "                                    \n",
    "            hwnn.load_state_dict(torch.load(model_path))\n",
    "            hwnn.eval()\n",
    "            models.append(hwnn)\n",
    "        \n",
    "        results = compare_models(models, np.arange(len(weight_variability_list)), max_samples=2000, get_accuracy=True, verbose=False)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"{ioqt}, {np.log2(1/wtqt)}, {weight_variability_list[i]}, {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"training/model.pth\"\n",
    "\n",
    "\n",
    "io_resolution = np.array([0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1])\n",
    "weight_quantisation_list = 2**np.array([6,6,6,6,6])\n",
    "wtqt_list = 1/weight_quantisation_list\n",
    "weight_variability_list = np.array([1e-1, 1e-2, 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "print(\"io, wtqt, wtvt, acc\")\n",
    "for ioqt in io_resolution:\n",
    "    for wtqt in wtqt_list:\n",
    "        models = []\n",
    "        for wtvt in weight_variability_list:\n",
    "            hwnn = PseudoHardwareNN(input_quantization=(True, ioqt),\n",
    "                                    weight_quantization=(True, wtqt, [-1,1]),\n",
    "                                    output_quantization=(True, ioqt),\n",
    "                                    weight_variance=(True, wtvt),\n",
    "                                    verbose=False)\n",
    "                                    \n",
    "            hwnn.load_state_dict(torch.load(model_path))\n",
    "            hwnn.eval()\n",
    "            models.append(hwnn)\n",
    "        \n",
    "        results = compare_models(models, np.arange(len(weight_variability_list)), max_samples=2000, get_accuracy=True, verbose=False)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"{ioqt}, {np.log2(1/wtqt)}, {weight_variability_list[i]}, {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"training/model.pth\"\n",
    "ann = NN()\n",
    "\n",
    "ann.load_state_dict(torch.load(model_path))\n",
    "ann.eval()\n",
    "\n",
    "models = [ann, ]\n",
    "names = [\"Software FFNN\", ]\n",
    "\n",
    "test_data = get_loaders(batch_size=1, train=False, dataset_path=\"datasets/\")\n",
    "max_samples = None\n",
    "\n",
    "\n",
    "compare_models(models, names, max_samples=max_samples, dataset=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interface.interfacer import PseudoHardwareNN, PseudoHardwareCNN\n",
    "cnn_path = \"training/cnn_weights.pth\"\n",
    "# cnn = CNN()\n",
    "ioqt = 1e-5\n",
    "hwcnn = PseudoHardwareCNN(input_quantization=(True, ioqt),\n",
    "                        weight_quantization=(False, 1, [-1,1]),\n",
    "                        output_quantization=(True, ioqt),\n",
    "                        weight_variance=(True, 0.001))\n",
    "\n",
    "# cnn.load_state_dict(torch.load(cnn_path))\n",
    "hwcnn.load_state_dict(torch.load(cnn_path))\n",
    "# cnn.eval()\n",
    "hwcnn.eval()\n",
    "\n",
    "models = [hwcnn]\n",
    "names = [\"CNN\"]\n",
    "\n",
    "test_data = get_loaders_cnn(batch_size=1, train=False)\n",
    "max_samples = None\n",
    "\n",
    "\n",
    "compare_models(models, names, max_samples=max_samples, dataset=test_data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "io,wtqt,wtvt,acc\n",
      "0.1, 10.0, 1.0, 0.1107\n",
      "0.1, 10.0, 0.5, 0.1049\n",
      "0.1, 10.0, 0.25, 0.1121\n",
      "0.1, 10.0, 0.125, 0.2063\n",
      "0.1, 10.0, 0.0625, 0.4444\n",
      "0.1, 10.0, 0.03125, 0.5641\n",
      "0.1, 10.0, 0.015625, 0.5802\n",
      "0.1, 10.0, 0.0078125, 0.5891\n",
      "0.1, 10.0, 1.0, 0.0936\n",
      "0.1, 10.0, 0.5, 0.0899\n",
      "0.1, 10.0, 0.25, 0.117\n",
      "0.1, 10.0, 0.125, 0.2313\n",
      "0.1, 10.0, 0.0625, 0.4437\n",
      "0.1, 10.0, 0.03125, 0.5682\n",
      "0.1, 10.0, 0.015625, 0.5849\n",
      "0.1, 10.0, 0.0078125, 0.5881\n",
      "0.1, 10.0, 1.0, 0.1017\n",
      "0.1, 10.0, 0.5, 0.0981\n",
      "0.1, 10.0, 0.25, 0.1146\n",
      "0.1, 10.0, 0.125, 0.2235\n",
      "0.1, 10.0, 0.0625, 0.4545\n",
      "0.1, 10.0, 0.03125, 0.5483\n",
      "0.1, 10.0, 0.015625, 0.5748\n",
      "0.1, 10.0, 0.0078125, 0.5846\n",
      "0.1, 10.0, 1.0, 0.0886\n",
      "0.1, 10.0, 0.5, 0.0866\n",
      "0.1, 10.0, 0.25, 0.1093\n",
      "0.1, 10.0, 0.125, 0.2129\n",
      "0.1, 10.0, 0.0625, 0.4224\n",
      "0.1, 10.0, 0.03125, 0.5476\n",
      "0.1, 10.0, 0.015625, 0.5858\n",
      "0.1, 10.0, 0.0078125, 0.5874\n",
      "0.1, 10.0, 1.0, 0.0919\n",
      "0.1, 10.0, 0.5, 0.0998\n",
      "0.1, 10.0, 0.25, 0.0986\n",
      "0.1, 10.0, 0.125, 0.1568\n",
      "0.1, 10.0, 0.0625, 0.4076\n",
      "0.1, 10.0, 0.03125, 0.551\n",
      "0.1, 10.0, 0.015625, 0.5753\n",
      "0.1, 10.0, 0.0078125, 0.5885\n",
      "0.1, 10.0, 1.0, 0.1104\n",
      "0.1, 10.0, 0.5, 0.0969\n",
      "0.1, 10.0, 0.25, 0.0937\n",
      "0.1, 10.0, 0.125, 0.1656\n",
      "0.1, 10.0, 0.0625, 0.4366\n",
      "0.1, 10.0, 0.03125, 0.517\n",
      "0.1, 10.0, 0.015625, 0.5926\n",
      "0.1, 10.0, 0.0078125, 0.5867\n",
      "0.1, 10.0, 1.0, 0.0986\n",
      "0.1, 10.0, 0.5, 0.0769\n",
      "0.1, 10.0, 0.25, 0.1141\n",
      "0.1, 10.0, 0.125, 0.2351\n",
      "0.1, 10.0, 0.0625, 0.401\n",
      "0.1, 10.0, 0.03125, 0.546\n",
      "0.1, 10.0, 0.015625, 0.5767\n",
      "0.1, 10.0, 0.0078125, 0.5898\n",
      "0.1, 10.0, 1.0, 0.1217\n",
      "0.1, 10.0, 0.5, 0.0998\n",
      "0.1, 10.0, 0.25, 0.101\n",
      "0.1, 10.0, 0.125, 0.2491\n",
      "0.1, 10.0, 0.0625, 0.4577\n",
      "0.1, 10.0, 0.03125, 0.5516\n",
      "0.1, 10.0, 0.015625, 0.5861\n",
      "0.1, 10.0, 0.0078125, 0.5887\n",
      "0.1, 10.0, 1.0, 0.0887\n",
      "0.1, 10.0, 0.5, 0.0991\n",
      "0.1, 10.0, 0.25, 0.0857\n",
      "0.1, 10.0, 0.125, 0.2031\n",
      "0.1, 10.0, 0.0625, 0.3813\n",
      "0.1, 10.0, 0.03125, 0.5515\n",
      "0.1, 10.0, 0.015625, 0.5854\n",
      "0.1, 10.0, 0.0078125, 0.5865\n",
      "0.1, 10.0, 1.0, 0.1049\n",
      "0.1, 10.0, 0.5, 0.0606\n",
      "0.1, 10.0, 0.25, 0.0883\n",
      "0.1, 10.0, 0.125, 0.1728\n",
      "0.1, 10.0, 0.0625, 0.446\n",
      "0.1, 10.0, 0.03125, 0.5515\n",
      "0.1, 10.0, 0.015625, 0.5756\n",
      "0.1, 10.0, 0.0078125, 0.5896\n"
     ]
    }
   ],
   "source": [
    "cnn_path = \"training/cnn_weights.pth\"\n",
    "from interface.interfacer import PseudoHardwareCNN\n",
    "\n",
    "io_resolution = np.array([0.1]*10)\n",
    "weight_quantisation_list = 2**np.array([10])\n",
    "wtqt_list = 1/weight_quantisation_list\n",
    "weight_variability_list = np.array([1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125, 0.015625, 0.0078125])\n",
    "\n",
    "test_data = get_loaders_cnn(batch_size=1, train=False)\n",
    "max_samples = None\n",
    "\n",
    "\n",
    "print(\"io,wtqt,wtvt,acc\")\n",
    "for ioqt in io_resolution:\n",
    "    for wtqt in wtqt_list:\n",
    "        models = []\n",
    "        for wtvt in weight_variability_list:\n",
    "            hwcnn = PseudoHardwareCNN(input_quantization=(False, ioqt),\n",
    "                                    weight_quantization=(False, wtqt, [-1,1]),\n",
    "                                    output_quantization=(False, ioqt),\n",
    "                                    weight_variance=(True, wtvt),)\n",
    "                                    \n",
    "            hwcnn.load_state_dict(torch.load(cnn_path))\n",
    "            hwcnn.eval()\n",
    "            models.append(hwcnn)\n",
    "        \n",
    "        # results = compare_models(models, np.arange(len(weight_variability_list)), max_samples=2000, get_accuracy=True, verbose=False)\n",
    "        results = compare_models(models, np.arange(len(weight_variability_list)), max_samples=max_samples, dataset=test_data, get_accuracy=True, verbose=False)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"{ioqt}, {np.log2(1/wtqt)}, {weight_variability_list[i]}, {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
